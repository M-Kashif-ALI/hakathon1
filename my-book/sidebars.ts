import type {SidebarsConfig} from '@docusaurus/plugin-content-docs';

// This runs in Node.js - Don't use client-side code here (browser APIs, JSX...)

/**
 * Creating a sidebar enables you to:
 - create an ordered group of docs
 - render a sidebar for each doc of that group
 - provide next/previous navigation

 The sidebars can be generated from the filesystem, or explicitly defined here.

 Create as many sidebars as you want.
 */
const sidebars: SidebarsConfig = {
  // By default, Docusaurus generates a sidebar from the docs folder structure
  // tutorialSidebar: [{type: 'autogenerated', dirName: '.'}],

  // Manual sidebar structure for ROS 2 Robotic Nervous System
  tutorialSidebar: [
    {
      type: 'category',
      label: 'ROS 2 Robotic Nervous System',
      items: [
        {
          type: 'category',
          label: 'Chapter 1: ROS 2 Architecture',
          items: [
            'ros2-nervous-system/ros2-architecture/index',
            'ros2-nervous-system/ros2-architecture/role-of-ros2',
            'ros2-nervous-system/ros2-architecture/nodes-topics-services',
          ],
        },
        {
          type: 'category',
          label: 'Chapter 2: Python Robot Control (rclpy)',
          items: [
            'ros2-nervous-system/python-robot-control/index',
            'ros2-nervous-system/python-robot-control/creating-nodes',
            'ros2-nervous-system/python-robot-control/pub-sub-patterns',
            'ros2-nervous-system/python-robot-control/ai-agent-integration',
          ],
        },
        {
          type: 'category',
          label: 'Chapter 3: Humanoid Structure with URDF',
          items: [
            'ros2-nervous-system/urdf-humanoid-structure/index',
            'ros2-nervous-system/urdf-humanoid-structure/urdf-links-joints',
            'ros2-nervous-system/urdf-humanoid-structure/kinematics',
            'ros2-nervous-system/urdf-humanoid-structure/simulation-control',
          ],
        },
      ],
    },
    {
      type: 'category',
      label: 'Digital Twin: Gazebo & Unity',
      items: [
        {
          type: 'category',
          label: 'Chapter 1: Physics Simulation with Gazebo',
          items: [
            'digital-twin/gazebo-simulation/index',
            'digital-twin/gazebo-simulation/physics-concepts',
            'digital-twin/gazebo-simulation/ros2-integration',
          ],
        },
        {
          type: 'category',
          label: 'Chapter 2: Environment & Interaction in Unity',
          items: [
            'digital-twin/unity-environment/index',
            'digital-twin/unity-environment/rendering',
            'digital-twin/unity-environment/interaction-scenarios',
          ],
        },
        {
          type: 'category',
          label: 'Chapter 3: Sensor Simulation',
          items: [
            'digital-twin/sensor-simulation/index',
            'digital-twin/sensor-simulation/lidar-simulation',
            'digital-twin/sensor-simulation/depth-camera-simulation',
            'digital-twin/sensor-simulation/imu-simulation',
            'digital-twin/sensor-simulation/ros2-data-flow',
          ],
        },
      ],
    },
    {
      type: 'category',
      label: 'Module 3: The AI-Robot Brain (NVIDIA Isaac)',
      items: [
        {
          type: 'category',
          label: 'Chapter 1: NVIDIA Isaac Sim',
          items: [
            'isaac-robot-brain/isaac-sim/index',
            'isaac-robot-brain/isaac-sim/photorealistic-simulation',
            'isaac-robot-brain/isaac-sim/synthetic-data-generation',
          ],
        },
        {
          type: 'category',
          label: 'Chapter 2: Isaac ROS',
          items: [
            'isaac-robot-brain/isaac-ros/index',
            'isaac-robot-brain/isaac-ros/perception-pipelines',
            'isaac-robot-brain/isaac-ros/visual-slam',
          ],
        },
        {
          type: 'category',
          label: 'Chapter 3: Navigation with Nav2',
          items: [
            'isaac-robot-brain/nav2-navigation/index',
            'isaac-robot-brain/nav2-navigation/path-planning',
            'isaac-robot-brain/nav2-navigation/humanoid-navigation',
          ],
        },
      ],
    },
    {
      type: 'category',
      label: 'Module 4: Vision-Language-Action (VLA) Integration',
      items: [
        {
          type: 'category',
          label: 'Chapter 1: Voice-to-Action Interfaces',
          items: [
            'vla-integration/voice-to-action/index',
            'vla-integration/voice-to-action/speech-recognition',
            'vla-integration/voice-to-action/command-processing',
            'vla-integration/voice-to-action/voice-command-examples',
            'vla-integration/voice-to-action/patterns-best-practices',
            'vla-integration/voice-to-action/troubleshooting',
          ],
        },
        {
          type: 'category',
          label: 'Chapter 2: Cognitive Planning with LLMs',
          items: [
            'vla-integration/cognitive-planning/index',
            'vla-integration/cognitive-planning/llm-task-planning',
            'vla-integration/cognitive-planning/ros2-mapping',
            'vla-integration/cognitive-planning/practical-examples',
            'vla-integration/cognitive-planning/mapping-strategies',
            'vla-integration/cognitive-planning/validation-techniques',
          ],
        },
        {
          type: 'category',
          label: 'Chapter 3: Capstone - The Autonomous Humanoid',
          items: [
            'vla-integration/autonomous-humanoid/index',
            'vla-integration/autonomous-humanoid/vla-pipeline',
            'vla-integration/autonomous-humanoid/workflow',
            'vla-integration/autonomous-humanoid/end-to-end-example',
            'vla-integration/autonomous-humanoid/simulation-examples',
            'vla-integration/autonomous-humanoid/error-handling',
            'vla-integration/autonomous-humanoid/performance-considerations',
            'vla-integration/autonomous-humanoid/summary',
          ],
        },
      ],
    },
  ],
};

export default sidebars;
